---
title: "Gestational Diabetes Prediction and Analysis in Pregnant Women"
author: "Ian Dsilva"
date: "2023-04-30"
output: html_document
---

## Loading Libraries
```{r lib, echo = TRUE, eval = TRUE, warning=FALSE, message=FALSE}
library(dplyr)
library(pROC)
library(tidyverse)
library(ROCR)
library(ggplot2)
library(caret)
library(Hmisc)
library(reshape2)
library(viridis)
library(glmnet)
library(pROC)
library(randomForest)
```

## Loading Dataset
```{r dataset, echo = TRUE, eval = TRUE, results="hide"}
df_diab <- read.csv('diabetes.csv')
```

## Data Cleaning

```{r cleaning, eval = TRUE}
# Check for missing values
any(missing(df_diab))
any(is.na(df_diab))
sum(is.na(df_diab))
```

## Exploratory Data Analysis
```{r EDA, eval = TRUE}
# Describing Dataset
head(df_diab)
summary(df_diab)
describe(df_diab)

# histogram for attribute
ggplot(gather(df_diab[, c(1,2,3,4,5,6,8)], variable, value), aes(x = value)) +
  geom_histogram(binwidth = 5, fill = "aquamarine4", color = "darkgreen") +
  facet_wrap(~variable, scales = "free") +
  labs(x = "Value", y = "Count", title = "Distrbution of values for each attribute")

# pie chart of the distribution of 0's and 1's in the Outcome variable
ggplot(df_diab, aes(x = "", fill = factor(df_diab$Outcome))) +
  geom_bar(width = 1, stat = "count") +
  scale_fill_manual(values = c("#576CBC", "#E21818"), name = "Outcome", labels = c("No Diabetes", "Diabetes")) +
  coord_polar(theta = "y") +
  labs(fill = "Outcome", title = "Outcome Distribution")

df_corr <- df_diab

df_corr$Outcome <- NULL

# Computing correlation matrix
cor_matrix <- cor(df_corr)

# Converting correlation matrix to long format
cor_df <- melt(cor_matrix)

# Plotting correlation matrix
ggplot(cor_df, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = round(value, 2)), size = 4, color = "white") +
  scale_fill_viridis_c(option = "viridis", na.value = "white") +
  labs(title = "Correlation Matrix", x = "", y = "") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1, color = 'black'),
        axis.text.y = element_text(size = 10, color = 'black'))

## Box Plot

# Reshaping the data into long format
df_long <- tidyr::gather(df_diab, key = "Feature", value = "Value", -Pregnancies)

# Creating a boxplot of all features
ggplot(df_long, aes(x = Feature, y = Value, fill = Feature)) +
  geom_boxplot(color = "black") +
  labs(title = "Boxplot of All Features",
       x = "Feature",
       y = "Value") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_discrete(name = "Feature")
```

## One Sample t-test

**Research Question: Is there sufficient evidence to suggest that the mean Blood Pressure of the population from which the given data set is sampled is significantly higher than a known value of 70 mm Hg, using a one-sample t-test?**

Null Hypothesis (H0): The mean Blood Pressure of the population is equal to 70 mm Hg. \
Alternate Hypothesis (H1): The mean Blood Pressure of the population is greater than 70 mm Hg.\
Alpha = 0.05

```{r onesample, eval = TRUE}
abs(qt(p = 0.05, df = 767, lower.tail = FALSE))

t.test(df_diab$BloodPressure, mu = 70, alternative = 'two.sided', conf.level = 0.90)
```

***Results: We Fail to Reject the Null Hypothesis*** \

**Research Question: Is there a significant difference in the average blood glucose levels of pregnant women with diabetes, compared to the general population average of 110 mg/dL?**\

Null Hypothesis (H0): There is no significant difference in the average blood glucose levels of pregnant women with diabetes compared to the general population average.\
Alternate Hypothesis (H1): There is a significant difference in the average blood glucose levels of pregnant women with diabetes compared to the general population average.\

Alpha = 0.05
```{r onesampleglu, eval = TRUE}
abs(qt(p = 0.05, df = 767, lower.tail = FALSE))

t.test(df_diab$Glucose, mu = 110, alternative = 'two.sided', conf.level = 0.90)
```

***Results: We Reject the Null Hypothesis***

## One Way Anova Hypothesis Testing

**Research Question: Perform a one-way ANOVA using the aov function in r to determines whether the diabetes is inherited or not?**\

Null Hypothesis (H0): There is no significant difference in the mean diabetes pedigree function among different outcome.\
Alternate Hypothesis (H1): There is a significant difference in the mean diabetes pedigree function among different outcome.\

```{r oneanova, eval = TRUE}
qf(0.95,1,766)

preg_res <- aov(DiabetesPedigreeFunction ~  Outcome, data = df_diab)
preg_res

summary(preg_res)
```
***Results: We Reject the Null Hypothesis***

## Multivariable Logistic Regression Hypothesis Testing

**Research Question: Perform multiple logistic regression predicting the relationship between several independent variables (Pregnancies, Glucose, Blood Pressure, Skin Thickness, Insulin, BMI, Diabetes Pedigree Function, Age) and the binary outcome of diabetes (Outcome).**\

Null Hypothesis (H0): There is no significant relationship between the independent variables (Glucose, Blood Pressure, Skin Thickness, Insulin, BMI, Diabetes Pedigree Function, Age) and the binary outcome (Outcome) of diabetes. \
Alternative Hypothesis (H1): There is a significant relationship between the independent variables and the binary outcome of diabetes.\

```{r MVL, eval = TRUE}
multi_log <- glm(Outcome ~ Pregnancies + Glucose + BloodPressure + SkinThickness + Insulin + BMI + DiabetesPedigreeFunction + Age,data = df_diab, family = binomial(link = "logit"))
multi_log 
summary(multi_log)
anova(multi_log)

exp(cbind(coef(multi_log), confint.default(multi_log)))

multi_predictions <- predict(multi_log, type = 'response')
multi_roc <- roc(df_diab$Outcome, multi_predictions)

plot(multi_roc , main = "ROC Curve", print.thres = TRUE, legacy.axes = TRUE)
cat("The area under the curve is:", multi_roc$auc, "\n")
```
***Results: We Reject the Null Hypothesis***

## Logistic Regression

```{r LR, eval = TRUE}
# Converting the columns to categorical or factor
df_diab$Outcome <- as.factor(df_diab$Outcome)

# Splitting the dataset into training and testing sets (80:20 split)
# Setting seed
set.seed(123)  
train_indices <- createDataPartition(df_diab$Outcome, p = 0.8, list = FALSE)
train_data <- df_diab[train_indices, ]
test_data <- df_diab[-train_indices, ]

# Fitting logistic regression model
log_reg <- glm(Outcome ~ ., data = train_data, family = "binomial")
log_reg

# Making predictions on test data
predictions <- predict(log_reg, newdata = test_data, type = "response")

# Convert predicted probabilities to binary outcomes (0 or 1)
predicted_outcomes <- ifelse(predictions > 0.5, 1, 0)

# Setting levels of predicted outcomes to match levels of test data outcomes
predicted_outcomes <- factor(predicted_outcomes, levels = levels(test_data$Outcome))

# Calculating the confusion matrix
confusion <- confusionMatrix(predicted_outcomes, test_data$Outcome)

# Extracting the confusion matrix values
confusion$table

# Extracting TP, FP, FN, TN from confusion matrix
tp <- confusion$table[2,2]
fp <- confusion$table[1,2]
fn <- confusion$table[2,1]
tn <- confusion$table[1,1]

# Calculating accuracy
accuracy <- (tp + tn) / sum(confusion$table)

# Calculating ROC (Receiver Operating Characteristic) curve
roc <- roc(test_data$Outcome, predictions)

# beta value for F-score
beta <- 1

# Calculate precision and recall
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)

# Calculate F-score
f_score <- (1 + beta^2) * (precision * recall) / ((beta^2 * precision) + recall)


# Print results
cat("Confusion Matrix:\n", confusion$table, "\n")
cat("TP:", tp, "\n")
cat("FP:", fp, "\n")
cat("FN:", fn, "\n")
cat("TN:", tn, "\n")
cat("Accuracy:", accuracy, "\n")
cat("AUC-ROC:", auc(roc), "\n")
cat("F-score:", f_score, "\n")

plot(roc, main = "ROC Curve", print.thres = TRUE, legacy.axes = TRUE)

summary(log_reg)
```

## Random Forest

```{r RF, eval = TRUE}
# Convert the Outcome column to factor
df_diab$Outcome <- as.factor(df_diab$Outcome)

# Split the dataset into training and testing sets (80:20 split)
# Set seed for reproducibility
set.seed(123)  
train_indices <- createDataPartition(df_diab$Outcome, p = 0.8, list = FALSE)
train_data <- df_diab[train_indices, ]
test_data <- df_diab[-train_indices, ]

# Prepare predictor variables and target variable
predictors <- train_data[, -which(names(train_data) == "Outcome")]
target <- train_data$Outcome

# Train the random forest model
rf_model <- randomForest(x = predictors, y = target, ntree = 500, mtry = sqrt(ncol(predictors)))
rf_model

# Make predictions on the test data
test_predictors <- test_data[, -which(names(test_data) == "Outcome")]
test_predictions <- predict(rf_model, newdata = test_predictors)

# Convert predicted outcomes to factors
test_predictions <- as.factor(test_predictions)

# Calculate the confusion matrix
confusion <- confusionMatrix(test_predictions, test_data$Outcome)
confusion$table
# Extract TP, FP, FN, TN from confusion matrix
tp <- confusion$table[2,2]
fp <- confusion$table[1,2]
fn <- confusion$table[2,1]
tn <- confusion$table[1,1]

# Calculate accuracy
accuracy <- (tp + tn) / sum(confusion$table)

# Calculate AUC-ROC
roc <- roc(test_data$Outcome, as.numeric(test_predictions))
auc_roc <- auc(roc)

# beta value for F-score
beta <- 1

# Calculate precision and recall
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)

# Calculate F-score
f_score <- (1 + beta^2) * (precision * recall) / ((beta^2 * precision) + recall)

# Print results
cat("TP:", tp, "\n")
cat("FP:", fp, "\n")
cat("FN:", fn, "\n")
cat("TN:", tn, "\n")
cat("Accuracy:", accuracy, "\n")
cat("AUC-ROC:", auc_roc, "\n")
cat("F-score:", f_score, "\n")

plot(roc, main = "ROC Curve", print.thres = TRUE, legacy.axes = TRUE)
```

## Conclusion

**1. We have developed a models that uses Logistic Regression and Random Forest.** \
**2. The best model has an accuracy of 0.81699, or 81.6%, in predicting gestational diabetes in pregnant women.** \
**3. We also used a one-way ANOVA model for the diabetes pedigree function, which determines whether the disease is inherited or not, and assessed it using the chance that an individual has inherited diabetes.** \
**4. We also performed a multivariate logistic regression, which clarifies whether a trait is important in predicting diabetes or not.** \
